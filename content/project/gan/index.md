---
title: GAN Generative Adversarial Network
subtitle: Brush-up notes collected from DeepLearning.AI GAN specialization and other resources.
summary: GAN empowers multityped generation (images, texts & audios) from ML/DL and the applications of GANs began to flourish in industry, academia and research, which further corroborate what AI Guru Andrew Ng affirmed - AI is the new electrity.
tags:
- Deep Learning
- GAN
date: "2020-10-17T00:00:00Z"

# Optional external URL for project (replaces project detail page).
external_link: ""

image:
  caption: Realistic human face generated by GAN.
  focal_point: Smart

links:
- icon: ""
  icon_pack: ""
  name: ""
  url: ""
url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.slides = ""

---

_DISCLAIMER: This post does not intend to explain "what is GAN?" or the math/theory behind GAN, but rather a brief and gentle notes on GAN verbalized in my own words.

Plenty of online blogposts has already covered how GAN work, interested readers are kindly invited to refer to the following sites:
* [GeeksforGeeks](https://www.geeksforgeeks.org/generative-adversarial-network-gan/)
* [Google Developers](https://developers.google.com/machine-learning/gan)_

Today we will focus on one of generative model - GAN Generative Adversarial Network, the other kind of generative model Variational Autoenconder may be discussed in the future. 

-----------------------------------------------------

## Two Components: Generator and Discriminator

In GANs, the model is majorly consisted of _**GENERATOR**_ and _**DISCRIMINATOR**_. As the names suggested, main task of _**GENERATOR**_ is to generate, meanwhile _**DISCRIMINATOR**_ is to discriminate, which in other words: to differentiate, distinguish, judge, and tell the difference. Two components have different inputs and outputs, and they are trained separately.

1. _**GENERATOR**_: 
    - INPUTS: noise vectors
    - OUTPUTS: generated vectors (same type as input or else)
    - VANILLA ARCHITECT: [ Linear, BatchNorm, ReLU ] * 4 blocks + [ Linear, Sigmoid] as final block
    - LOSS: binary crossentropy BCE between fake and real predictions

The noise vector has an important role as input to generator, ensuring that outputs from the generator are not all the same. The dimensions of desired outputs, such as images or texts, are defined at the the Linear layer of final block.

2. _**DISCRIMINATOR**_:
    - INPUTS: outputs generated by Generator
    - OUTPUTS: classification result
    - VANILLA ARCHITECT: [ Linear, LeakyReLU ] * 4 blocks + [ Linear ] as final block
    - LOSS: mean of binary crossentropy BCE of both fake-fake and real-real predictions

To be precise, 1-D tensor, which is a single number, is defined at the Linear layer of final block. A sigmoid is not necessary after the output layer, since it is included in the loss function.

:star: Of course, the Linear layer can be replaced by CNN: blocks [ ConvTranspose2D, BatchNorm, ReLU ] and final block [ ConvTranspose2D, Tanh ] in generator and [ Conv2D, BatchNorm, LeakyReLU ] and final block [ Conv2D ] in discriminator. 

#### Dying ReLU 
A phenomenon where the parameters stop chaning when negative values passed consistently to a ReLU, which result in a zero gradient. 
:heavy_check_mark: A solution to this is use Leaky ReLU.

#### BCE Vanishing Gradients
GAN's goal is to make real and generated distributions look similar, however, during training discriminator usually get to good accuracy easily but generator remains performing poorly. BCE loss contain flat regions, so model stops learning.
:heavy_check_mark: A solution to this is use Wasserstein Loss W-loss. W-loss approximated the Earth Mover's Distance EMD between real and generated distributions. EMD is a function of the effort to make a distribution equal to another.

#### Mode Collapse
A typical phenomenon happens with real-world datasets, and particularly when model trains with BCE. Modes are peaks in the distributions of features, for example the famous MNIST digit dataset would have 10 modes for digits from 0 to 9. Mode collapse happens when generator gets stuck in one mode, such as generator only generates digit "1" but not other digits.
:heavy_check_mark: A solution to this is use Wasserstein Loss W-loss.

#### Wasserstein Loss W-loss
GANs can be leveraged with W-loss, different from BCE (which distinguish between 0 and 1), meanwhile W-loss makes output no longer bounded and represents any real values. GAN using w-loss is thus called WGAN and the differences calculated between expected values and discriminator's predictions are then named critic. The nature of critic helps to improve without degrading its feedback back to the generator.
**Additional condition on W-loss**: 1-Lipschitz continuous, the norm of its gradient needs to be at most 1. This assures W-loss function to be not obly continuous and differentiable, but also maintain stability during training (which further ensures the validity of underlying EMD).
**Methods of 1-L continuity enforcement**
    1. Weight clipping: forcing the weights of the critic to a fixed interval. Might involve a hyperparameter tuning to find the optimal range to clip the weights. Downside - limits the learning ability of the critic because critic and weights can't take on many different values and not easy to find good loop optimal to be in.
    2. Gradient penalty: adding a regularization term of the critic's gradient to the W-loss when its gradients norm is higher than 1. Instead of checking all critic gradient at every possible point of the feature spacr, it takes some random points by interpolaing between real and fake examples, gets the norm of the critic gradients of these interpolations and minus 1 to the norm to penalzing any value outside of 1. GP generally tends to work better than weight clipping.
**Spectral norm** normalizes the weight matrices in the discriminator by their corresponding spectral norm, which helps control the Lipschitz constant of the discriminator. It assures validity W-loss for the discriminator/critic in WGAN.
__references:__ 
1. [Wasserstein GAN (Arjovsky, Chintala, and Bottou, 2017)](https://arxiv.org/abs/1701.07875)
2. [Improved Training of Wasserstein GANs (Gulrajani et al., 2017)](https://arxiv.org/abs/1704.00028)
3. [From GAN to WGAN (Weng, 2017)](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html)
4. [Spectral Normalization for Generative Adversarial Networks (Miyato et al. 2018)](https://arxiv.org/abs/1802.05957)

## Conditional and Controllable Generation
Sometimes we would like the GAN to produce certain classes, for example only Siamese cat images generated from GAN for cat, or images with certain features, human with green hair or red hair from GAN for face image generation.

1. _**CONDITIONAL GENERATION**_: produce examples from the desired classes.
    - Generator INPUTS: concatenated vector of one-hot vector of class and noise vector 
    - Discriminator INPUTS: generator's output and labeled training dataset, pratically one-hot class matrices are fed in on additional channels, where desired class matrix is all-1 and of size same as image height and width.
  
2. _**CONTROLLABLE GENERATION**_: produce examples with the desired features.
    - Generator INPUTS: tweaked noise vector
:eyes: Precisely, in noise feature spaces, we approach one vector towards another by means of linear interpolation or other methods to modify the direction. We can find direction using the gradient of pre-trained classifiers and it only modifies just the noise vector until the feature emerges. The non-desired images classified are further penalized to move the noise vector towards right direction. In this scenario, stochastic gradient ascent is used to find local maxima of noise vector. However, challenge may arise:
  **Noise vector entanglement**: since noise vector may not have enough dimensions relative to the number of output features, highly correlated output features make impossible to map 1-to-1. If we want images of face with beards, it is more likely to have human faces full of masculine features with beards than girl with big hipster beards.
  **Disentanglement**: disentangled noise space often called latent factors of variation and troubleshoot the entanglement with the two methods beneath.
    1. Label data and index the one-hot vector of class to the noise vector. :x: difficult for continuous classes
    2. Loss function regularization: add a regularization term to the loss function, such as L2, classifier gradient or other advanced unsupervised techniques, in order to isolate the target feature more by holding the classes outside of the target class constant.
      - L2 details:
      ```python
      # Steps: 1) Calculate the change between the original and current  classifications as a tensor by indexing into the other classes indices.
      #        2) Calculate the norm (magnitude) of changes per example.
      #        3) Multiply the mean of the example norms by the penalty weight, must be negative. 
      ```

